{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10603a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import cv2 as cv #Importamos la librería de OpenCV\n",
    "import matplotlib.pyplot as plt #Importamos el módulo matplotlib para mostrar gráficos matemáticos e imágenes (como gráficos). \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b02a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCLASES:\\nTriangulo\\nRectangulo\\nPentagono (regular)\\nHexágono (regular)\\nCirculo\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CLASES:\n",
    "Triangulo\n",
    "Rectangulo\n",
    "Pentagono (regular)\n",
    "Hexágono (regular)\n",
    "Circulo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1952ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "imageSize = (64, 64)\n",
    "n_triangulos = 100\n",
    "n_rectangulos = 100\n",
    "n_pentagonos = 100\n",
    "n_hexagonos = 100\n",
    "n_circulos = 100\n",
    "\n",
    "\n",
    "#RECTANGULOS\n",
    "\n",
    "minOriginR = 0\n",
    "maxOriginR = 44\n",
    "minHeightWidthR = 6\n",
    "maxHeightWidthR = 20\n",
    "\n",
    "\n",
    "#RESTOPOLIGONOS\n",
    "minOriginP = 13\n",
    "maxOriginP = 51\n",
    "minRadio = 13\n",
    "maxRadio = 19\n",
    "minRotation = 0\n",
    "maxRotation = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781d7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaTriangulos():\n",
    "    for i in range(acum, acum+n_triangulos):\n",
    "        x = random.randrange(minOriginP, maxOriginP)\n",
    "        y = random.randrange(minOriginP, maxOriginP)\n",
    "        radius = random.randrange(minRadio, maxRadio)\n",
    "        rotate = random.randrange(minRotation, maxRotation)\n",
    "        image = Image.new('RGB', imageSize, 'white')  # could also open an existing image here to draw shapes over it\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.regular_polygon((x, y, radius), 3, rotation=rotate, fill='black', outline='black')  # can vary this bit to draw different shapes in different positions\n",
    "        image.save('./Dataset/triangulos/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45e9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum += n_triangulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2a0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaRectangulos():\n",
    "    for i in range(acum, acum+n_rectangulos):\n",
    "        x = random.randrange(minOriginR, maxOriginR)\n",
    "        y = random.randrange(minOriginR, maxOriginR)\n",
    "        u = x + random.randrange(minHeightWidthR, maxHeightWidthR)\n",
    "        v = y + random.randrange(minHeightWidthR, maxHeightWidthR)\n",
    "        image = Image.new('RGB', imageSize, 'white')  # could also open an existing image here to draw shapes over it\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.rectangle((x,y,u,v), fill='black', outline='black')  # can vary this bit to draw different shapes in different positions\n",
    "        image.save('./Dataset/rectangulos/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c97d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum += n_rectangulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c2610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaPentagonos():\n",
    "    for i in range(acum, acum+n_pentagonos):\n",
    "        x = random.randrange(minOriginP, maxOriginP)\n",
    "        y = random.randrange(minOriginP, maxOriginP)\n",
    "        radius = random.randrange(minRadio, maxRadio)\n",
    "        rotate = random.randrange(minRotation, maxRotation)\n",
    "        image = Image.new('RGB', imageSize, 'white')  # could also open an existing image here to draw shapes over it\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.regular_polygon((x, y, radius), 5, rotation=rotate, fill='black', outline='black')  # can vary this bit to draw different shapes in different positions\n",
    "        image.save('./Dataset/pentagonos/'+str(i)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad6275cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum += n_pentagonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e456e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaHexagonos():\n",
    "    for i in range(acum, acum+n_hexagonos):\n",
    "        x = random.randrange(minOriginP, maxOriginP)\n",
    "        y = random.randrange(minOriginP, maxOriginP)\n",
    "        radius = random.randrange(minRadio, maxRadio)\n",
    "        rotate = random.randrange(minRotation, maxRotation)\n",
    "        image = Image.new('RGB', imageSize, 'white')  # could also open an existing image here to draw shapes over it\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.regular_polygon((x, y, radius), 6, rotation=rotate, fill='black', outline='black')  # can vary this bit to draw different shapes in different positions\n",
    "        image.save('./Dataset/hexagonos/'+str(i)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de97916",
   "metadata": {},
   "outputs": [],
   "source": [
    "acum += n_hexagonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c75945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaCirculos():\n",
    "    for i in range(acum, acum+n_circulos):\n",
    "        x = random.randrange(minOriginP, maxOriginP)\n",
    "        y = random.randrange(minOriginP, maxOriginP)\n",
    "        u = x + random.randrange(minHeightWidthR, maxHeightWidthR)\n",
    "        v = y + random.randrange(minHeightWidthR, maxHeightWidthR)\n",
    "        image = Image.new('RGB', imageSize, 'white')  # could also open an existing image here to draw shapes over it\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.ellipse((x, y, u,v), fill='black', outline='black')  # can vary this bit to draw different shapes in different positions\n",
    "        image.save('./Dataset/circulos/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3187ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "acum = 0\n",
    "generaTriangulos()\n",
    "acum += n_triangulos\n",
    "generaRectangulos()\n",
    "acum += n_rectangulos\n",
    "generaPentagonos()\n",
    "acum += n_pentagonos\n",
    "generaHexagonos()\n",
    "acum += n_hexagonos\n",
    "generaCirculos()\n",
    "acum += n_circulos\n",
    "print(acum)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83441ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf9054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8bd405",
   "metadata": {},
   "source": [
    "Para comenzar, la red toma como entrada los pixeles de una imagen. Si tenemos una imagen con nxm pixeles de alto y ancho equivalen a n * m neuronas. Por lo que en nuestro ejemplo serán 64 * 64 = 4096 neuronas. Si las imágenes fueran a color (RGB) en su lugar utiliriamos 64 * 64 * 3 ... \n",
    "\n",
    "Estas neuronas constituyen nuestra capa de entrada.\n",
    "\n",
    "### Preprocesamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c12a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "878649af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = \"./Dataset/\"\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a90eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 files belonging to 5 classes.\n",
      "Using 400 files for training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d7968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c303d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 files belonging to 5 classes.\n",
      "Using 100 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "598f0ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['circulos', 'hexagonos', 'pentagonos', 'rectangulos', 'triangulos']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40e6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ME CRASHEA FUERTE\n",
    "#plt.figure(figsize=(5, 5))\n",
    "#for images, labels in train_ds.take(1):\n",
    "#  for i in range(1):\n",
    "#    ax = plt.subplot(3, 3, i + 1)\n",
    "#    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#    plt.title(class_names[labels[i]])\n",
    "#    plt.axis(\"off\")\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b479764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d17241",
   "metadata": {},
   "source": [
    "image_batch es un tensor de la forma (32, 180, 180, 3) . Este es un lote de 32 imágenes de forma 180x180x3 (la última dimensión se refiere a los canales de color RGB). El label_batch es un tensor de la forma (32,) , estas son las etiquetas correspondientes a las 32 imágenes.\n",
    "\n",
    "Puede llamar a .numpy() en cualquiera de estos tensores para convertirlos en numpy.ndarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa72de",
   "metadata": {},
   "source": [
    "#### Estandarizar los datos\n",
    "Los valores del canal RGB están en el rango [0, 255] . Esto no es ideal para una red neuronal; en general, debe buscar que sus valores de entrada sean pequeños.\n",
    "\n",
    "Aquí, estandarizará los valores para que estén en el rango [0, 1] usando tf.keras.layers.Rescaling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed259de",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cb84a",
   "metadata": {},
   "source": [
    "Hay dos formas de usar esta capa. Puede aplicarlo al conjunto de datos llamando a Dataset.map :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a470df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53aee6c",
   "metadata": {},
   "source": [
    "### Configurar el conjunto de datos para el rendimiento\n",
    "Asegurémonos de utilizar la captación previa almacenada en búfer para que pueda obtener datos del disco sin que la E/S se convierta en un bloqueo. Estos son dos métodos importantes que debe usar al cargar datos:\n",
    "\n",
    "- Dataset.cache mantiene las imágenes en la memoria después de que se cargan fuera del disco durante la primera época. Esto asegurará que el conjunto de datos no se convierta en un cuello de botella mientras entrena su modelo. Si su conjunto de datos es demasiado grande para caber en la memoria, también puede usar este método para crear un caché en disco de alto rendimiento.\n",
    "- Dataset.prefetch superpone el preprocesamiento de datos y la ejecución del modelo durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cedce97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70be90",
   "metadata": {},
   "source": [
    "### entrenar a un modelo\n",
    "Para completar, mostrará cómo entrenar un modelo simple utilizando los conjuntos de datos que acaba de preparar.\n",
    "\n",
    "El modelo secuencial consta de tres bloques de convolución ( tf.keras.layers.Conv2D ) con una capa de agrupación máxima ( tf.keras.layers.MaxPooling2D ) en cada uno de ellos. Hay una capa totalmente conectada ( tf.keras.layers.Dense ) con 128 unidades encima que se activa mediante una función de activación de ReLU ( 'relu' ). Este modelo no se ha ajustado de ninguna manera: el objetivo es mostrarle la mecánica utilizando los conjuntos de datos que acaba de crear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8ab992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29170d0",
   "metadata": {},
   "source": [
    "Elija el optimizador tf.keras.optimizers.Adam y la función de pérdida tf.keras.losses.SparseCategoricalCrossentropy . Para ver la precisión del entrenamiento y la validación para cada época de entrenamiento, pase el argumento de metrics a Model.compile ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba5eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbb856d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9581 - accuracy: 0.5775 - val_loss: 0.9261 - val_accuracy: 0.5800\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.8077 - accuracy: 0.6475 - val_loss: 0.8813 - val_accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.7027 - accuracy: 0.6825 - val_loss: 0.8285 - val_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.5918 - accuracy: 0.7575 - val_loss: 0.7928 - val_accuracy: 0.6200\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.5020 - accuracy: 0.8075 - val_loss: 0.8408 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.4923 - accuracy: 0.8025 - val_loss: 0.8538 - val_accuracy: 0.5600\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.4289 - accuracy: 0.8025 - val_loss: 0.8289 - val_accuracy: 0.5900\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.3315 - accuracy: 0.8825 - val_loss: 0.7698 - val_accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.2442 - accuracy: 0.9225 - val_loss: 0.7534 - val_accuracy: 0.6200\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.1978 - accuracy: 0.9525 - val_loss: 0.7964 - val_accuracy: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c42673c40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0491d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2a3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# Crea una instancia del modelo\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ee8d8",
   "metadata": {},
   "source": [
    "Escoge un optimizador y una funcion de perdida para el entrenamiento de tu modelo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdaf1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24db84",
   "metadata": {},
   "source": [
    "Escoge metricas para medir la perdida y exactitud del modelo. Estas metricas acumulan los valores cada epoch y despues imprimen el resultado total.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2cf0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eaa6c5",
   "metadata": {},
   "source": [
    "Utiliza tf.GradientTape para entrenar el modelo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd002db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9fc6f0",
   "metadata": {},
   "source": [
    "Prueba el modelo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39ffde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  predictions = model(images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a383d428",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m      5\u001b[0m   train_step(images, labels)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_images, test_labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_ds\u001b[49m:\n\u001b[0;32m      8\u001b[0m   test_step(test_images, test_labels)\n\u001b[0;32m     10\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Perdida: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Exactitud: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Perdida de prueba: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Exactitud de prueba: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ds' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  template = 'Epoch {}, Perdida: {}, Exactitud: {}, Perdida de prueba: {}, Exactitud de prueba: {}'\n",
    "  print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))\n",
    "\n",
    "  # Reinicia las metricas para el siguiente epoch.\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d097737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a6233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb53fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1bb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
